{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# !pip install -U ultralytics\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Your base config ---\n",
    "DATA_YAML = \"defect_detection_3d_printing_yolo/data.yaml\"\n",
    "PROJECT_ROOT = \"runs15\"         # all experiments go here\n",
    "EPOCHS = 15\n",
    "IMGSZ = 896\n",
    "\n",
    "# Choose your two models here (the assignment says \"both models\")\n",
    "MODELS = [\n",
    "    \"yolo11n.pt\",\n",
    "]\n",
    "\n",
    "# Sweeps required by assignment\n",
    "LR_MULTS = [1.0, 5.0, 0.2]     # default, 5x, 0.2x\n",
    "BATCHES  = [8, 16, 32]         # batch sweep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa9c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_name(model_ckpt: str, imgsz: int, batch: int, lr_mult: float):\n",
    "    base = Path(model_ckpt).stem  # \"yolo11s\"\n",
    "    lr_tag = f\"lr{lr_mult:g}x\"     # lr1x, lr5x, lr0.2x\n",
    "    return f\"{base}_img{imgsz}_b{batch}_{lr_tag}\"\n",
    "\n",
    "def run_dir(project: str, name: str) -> Path:\n",
    "    return Path(project) / name\n",
    "\n",
    "def load_results_csv(project: str, name: str) -> pd.DataFrame:\n",
    "    csv_path = run_dir(project, name) / \"results.csv\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing results.csv at: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # YOLO logs epochs starting at 0 in the csv typically; we'll create a 1-based epoch column for plotting\n",
    "    if \"epoch\" in df.columns:\n",
    "        df[\"epoch_1based\"] = df[\"epoch\"] + 1\n",
    "    else:\n",
    "        # fallback: assume row index corresponds to epoch\n",
    "        df[\"epoch_1based\"] = df.index + 1\n",
    "    return df\n",
    "\n",
    "def pick_col(df: pd.DataFrame, candidates):\n",
    "    \"\"\"Return the first existing column name from candidates, else None.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def plot_metric(df: pd.DataFrame, y_col: str, title: str, label: str = None, x_col: str = \"epoch_1based\"):\n",
    "    plt.plot(df[x_col], df[y_col], marker=\"o\", linewidth=1.5, label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "def finalize_plot(ylabel: str, legend=True):\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend:\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6cc3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(model_ckpt: str, imgsz: int, batch: int, lr_mult: float, project: str, epochs: int):\n",
    "    name = run_name(model_ckpt, imgsz, batch, lr_mult)\n",
    "\n",
    "    # Skip if already trained (optional)\n",
    "    out_dir = run_dir(project, name)\n",
    "    if (out_dir / \"results.csv\").exists():\n",
    "        print(f\"[SKIP] {name} already exists.\")\n",
    "        return name\n",
    "\n",
    "    model = YOLO(model_ckpt)\n",
    "\n",
    "    # Ultralytics hyperparams:\n",
    "    # - lr0 is initial learning rate; default depends on model/task, so we get \"default ×\" by not setting it.\n",
    "    # - BUT for 5× and 0.2× we need a baseline. The cleanest way is:\n",
    "    #   1) run default with lr_mult=1.0 (no lr0 override)\n",
    "    #   2) for others, override lr0 relative to a chosen baseline value you define\n",
    "    #\n",
    "    # If your class expects strict \"× default\", then you should set BASE_LR0 to the default used in your training config.\n",
    "    # Common default for YOLO detect is around 0.01, but verify in your training logs.\n",
    "    BASE_LR0 = 0.01\n",
    "\n",
    "    train_kwargs = dict(\n",
    "        data=DATA_YAML,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,\n",
    "        project=project,\n",
    "        name=name,\n",
    "        # device=0,  # uncomment if you want GPU index\n",
    "        plots=True,  # YOLO will generate built-in plots (results, PR, F1, confusion, etc.)\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    if lr_mult != 1.0:\n",
    "        train_kwargs[\"lr0\"] = BASE_LR0 * lr_mult\n",
    "\n",
    "    print(f\"[TRAIN] {name}\")\n",
    "    model.train(**train_kwargs)\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96b72d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] yolo11s_img896_b16_lr1x\n",
      "New https://pypi.org/project/ultralytics/8.4.13 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.12  Python-3.12.10 torch-2.10.0+cpu CPU (13th Gen Intel Core i9-13900H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=defect_detection_3d_printing_yolo/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=896, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolo11s_img896_b16_lr1x, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs15, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\ricky\\Documents\\24641_Project\\runs\\detect\\runs15\\yolo11s_img896_b16_lr1x, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820569  ultralytics.nn.modules.head.Detect           [3, 16, None, [128, 256, 512]]\n",
      "YOLO11s summary: 182 layers, 9,428,953 parameters, 9,428,937 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 60.030.0 MB/s, size: 25.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ricky\\Documents\\24641_Project\\defect_detection_3d_printing_yolo\\train\\labels.cache... 240 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 240/240  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 105.819.1 MB/s, size: 39.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ricky\\Documents\\24641_Project\\defect_detection_3d_printing_yolo\\valid\\labels.cache... 30 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 30/30  0.0s\n",
      "Plotting labels to C:\\Users\\ricky\\Documents\\24641_Project\\runs\\detect\\runs15\\yolo11s_img896_b16_lr1x\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 896 train, 896 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\ricky\\Documents\\24641_Project\\runs\\detect\\runs15\\yolo11s_img896_b16_lr1x\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      2.677      7.839      2.565         53        896: 33% ━━━━──────── 5/15 1.4it/s 5:26<7.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_ckpt \u001b[38;5;129;01min\u001b[39;00m MODELS:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m lr_mult \u001b[38;5;129;01min\u001b[39;00m LR_MULTS:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         name = \u001b[43mtrain_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMGSZ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlr_mult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROJECT_ROOT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m         all_runs.append(name)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# --- Batch sweep at default LR (1x) ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain_one\u001b[39m\u001b[34m(model_ckpt, imgsz, batch, lr_mult, project, epochs)\u001b[39m\n\u001b[32m     35\u001b[39m     train_kwargs[\u001b[33m\"\u001b[39m\u001b[33mlr0\u001b[39m\u001b[33m\"\u001b[39m] = BASE_LR0 * lr_mult\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[TRAIN] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\ultralytics\\engine\\model.py:774\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    771\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    772\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:244\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:442\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.scale(\u001b[38;5;28mself\u001b[39m.loss).backward()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m     last_opt_step = ni\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:693\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform a single step of the training optimizer with gradient clipping and EMA update.\"\"\"\u001b[39;00m\n\u001b[32m    692\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.unscale_(\u001b[38;5;28mself\u001b[39m.optimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.step(\u001b[38;5;28mself\u001b[39m.optimizer)\n\u001b[32m    695\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:42\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:232\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    230\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    231\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[43m_clip_grads_with_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:42\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ricky\\Documents\\24641_Project\\yolo-env\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:169\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    165\u001b[39m clip_coef = max_norm / (total_norm + \u001b[32m1e-6\u001b[39m)\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# when the gradients do not reside in CPU memory.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m clip_coef_clamped = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads.items():\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_grads, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    172\u001b[39m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[32m    173\u001b[39m     ):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_runs = []\n",
    "\n",
    "# --- LR sweep at default batch 16 ---\n",
    "for model_ckpt in MODELS:\n",
    "    for lr_mult in LR_MULTS:\n",
    "        name = train_one(\n",
    "            model_ckpt=model_ckpt,\n",
    "            imgsz=IMGSZ,\n",
    "            batch=16,\n",
    "            lr_mult=lr_mult,\n",
    "            project=PROJECT_ROOT,\n",
    "            epochs=EPOCHS,\n",
    "        )\n",
    "        all_runs.append(name)\n",
    "\n",
    "# --- Batch sweep at default LR (1x) ---\n",
    "for model_ckpt in MODELS:\n",
    "    for b in BATCHES:\n",
    "        name = train_one(\n",
    "            model_ckpt=model_ckpt,\n",
    "            imgsz=IMGSZ,\n",
    "            batch=b,\n",
    "            lr_mult=1.0,\n",
    "            project=PROJECT_ROOT,\n",
    "            epochs=EPOCHS,\n",
    "        )\n",
    "        all_runs.append(name)\n",
    "\n",
    "print(\"\\nFinished / queued runs:\")\n",
    "for r in all_runs:\n",
    "    print(\" -\", r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate columns (Ultralytics results.csv naming varies slightly by version)\n",
    "COL_VAL_LOSS = [\n",
    "    \"val/box_loss\", \"metrics/val_box_loss\", \"val/box_loss\"\n",
    "]\n",
    "COL_MAP5095 = [\n",
    "    \"metrics/mAP50-95(B)\", \"metrics/mAP50-95\", \"metrics/mAP50-95(B)\", \"metrics/mAP50-95\"\n",
    "]\n",
    "COL_MAP50 = [\n",
    "    \"metrics/mAP50(B)\", \"metrics/mAP50\", \"metrics/mAP50(B)\", \"metrics/mAP50\"\n",
    "]\n",
    "COL_PREC = [\n",
    "    \"metrics/precision(B)\", \"metrics/precision\", \"metrics/precision(B)\"\n",
    "]\n",
    "COL_RECALL = [\n",
    "    \"metrics/recall(B)\", \"metrics/recall\", \"metrics/recall(B)\"\n",
    "]\n",
    "COL_TRAIN_BOX = [\"train/box_loss\"]\n",
    "COL_TRAIN_CLS = [\"train/cls_loss\"]\n",
    "COL_TRAIN_DFL = [\"train/dfl_loss\"]\n",
    "\n",
    "def plot_required_for_run(project: str, name: str):\n",
    "    df = load_results_csv(project, name)\n",
    "\n",
    "    # Filter epochs 1..15 (already should be 15, but keeps it explicit)\n",
    "    df = df[(df[\"epoch_1based\"] >= 1) & (df[\"epoch_1based\"] <= 15)].copy()\n",
    "\n",
    "    val_box_col = pick_col(df, COL_VAL_LOSS)\n",
    "    map5095_col = pick_col(df, COL_MAP5095)\n",
    "    map50_col   = pick_col(df, COL_MAP50)\n",
    "    prec_col    = pick_col(df, COL_PREC)\n",
    "    rec_col     = pick_col(df, COL_RECALL)\n",
    "    train_box   = pick_col(df, COL_TRAIN_BOX)\n",
    "    train_cls   = pick_col(df, COL_TRAIN_CLS)\n",
    "    train_dfl   = pick_col(df, COL_TRAIN_DFL)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Columns found:\",\n",
    "          {\"val_box\": val_box_col, \"mAP50-95\": map5095_col, \"mAP50\": map50_col,\n",
    "           \"prec\": prec_col, \"recall\": rec_col,\n",
    "           \"train_box\": train_box, \"train_cls\": train_cls, \"train_dfl\": train_dfl})\n",
    "\n",
    "    # 1) Validation loss vs epochs\n",
    "    if val_box_col:\n",
    "        plt.figure()\n",
    "        plot_metric(df, val_box_col, f\"{name}: Validation box_loss vs Epochs\", label=\"val box_loss\")\n",
    "        finalize_plot(\"Loss\")\n",
    "    else:\n",
    "        print(\"Could not find a validation loss column for this run.\")\n",
    "\n",
    "    # 2) mAP50–95 vs epochs\n",
    "    if map5095_col:\n",
    "        plt.figure()\n",
    "        plot_metric(df, map5095_col, f\"{name}: mAP50-95 vs Epochs\", label=\"mAP50-95\")\n",
    "        finalize_plot(\"mAP50-95\")\n",
    "    else:\n",
    "        print(\"Could not find mAP50-95 column for this run.\")\n",
    "\n",
    "    # 3) box_loss, cls_loss, dfl_loss, Precision, Recall, mAP50 vs epochs\n",
    "    plt.figure()\n",
    "    did_any = False\n",
    "    for col, lab in [(train_box, \"train box_loss\"), (train_cls, \"train cls_loss\"), (train_dfl, \"train dfl_loss\")]:\n",
    "        if col:\n",
    "            plt.plot(df[\"epoch_1based\"], df[col], marker=\"o\", linewidth=1.5, label=lab)\n",
    "            did_any = True\n",
    "    if did_any:\n",
    "        plt.title(f\"{name}: Train losses vs Epochs\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    else:\n",
    "        print(\"Could not find train losses (box/cls/dfl) columns.\")\n",
    "\n",
    "    plt.figure()\n",
    "    did_any = False\n",
    "    for col, lab in [(prec_col, \"Precision\"), (rec_col, \"Recall\"), (map50_col, \"mAP50\")]:\n",
    "        if col:\n",
    "            plt.plot(df[\"epoch_1based\"], df[col], marker=\"o\", linewidth=1.5, label=lab)\n",
    "            did_any = True\n",
    "    if did_any:\n",
    "        plt.title(f\"{name}: Precision / Recall / mAP50 vs Epochs\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Metric\"); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    else:\n",
    "        print(\"Could not find Precision/Recall/mAP50 columns.\")\n",
    "\n",
    "# Run for all experiment folders we made\n",
    "for name in all_runs:\n",
    "    # de-dup names if any repeats\n",
    "    pass\n",
    "\n",
    "for name in sorted(set(all_runs)):\n",
    "    plot_required_for_run(PROJECT_ROOT, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_runs(project: str, run_names: list, title: str):\n",
    "    # Load dfs\n",
    "    dfs = {}\n",
    "    for rn in run_names:\n",
    "        df = load_results_csv(project, rn)\n",
    "        df = df[(df[\"epoch_1based\"] >= 1) & (df[\"epoch_1based\"] <= 15)].copy()\n",
    "        dfs[rn] = df\n",
    "\n",
    "    # Determine columns from the first df that has them\n",
    "    any_df = next(iter(dfs.values()))\n",
    "    val_box_col = pick_col(any_df, COL_VAL_LOSS) or pick_col(any_df, [\"val/box_loss\", \"metrics/val_box_loss\"])\n",
    "    map5095_col = pick_col(any_df, COL_MAP5095)\n",
    "    map50_col   = pick_col(any_df, COL_MAP50)\n",
    "\n",
    "    # Validation loss comparison\n",
    "    if val_box_col:\n",
    "        plt.figure()\n",
    "        for rn, df in dfs.items():\n",
    "            if val_box_col in df.columns:\n",
    "                plot_metric(df, val_box_col, f\"{title}: Validation Loss\", label=rn)\n",
    "        finalize_plot(\"Val loss\")\n",
    "    else:\n",
    "        print(f\"[{title}] Could not find a validation loss column.\")\n",
    "\n",
    "    # Accuracy comparison (mAP50-95)\n",
    "    if map5095_col:\n",
    "        plt.figure()\n",
    "        for rn, df in dfs.items():\n",
    "            if map5095_col in df.columns:\n",
    "                plot_metric(df, map5095_col, f\"{title}: mAP50-95\", label=rn)\n",
    "        finalize_plot(\"mAP50-95\")\n",
    "    else:\n",
    "        print(f\"[{title}] Could not find mAP50-95 column.\")\n",
    "\n",
    "    # Optional: mAP50 comparison\n",
    "    if map50_col:\n",
    "        plt.figure()\n",
    "        for rn, df in dfs.items():\n",
    "            if map50_col in df.columns:\n",
    "                plot_metric(df, map50_col, f\"{title}: mAP50\", label=rn)\n",
    "        finalize_plot(\"mAP50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34640e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR sweep groups: for each model, compare lr1x vs lr5x vs lr0.2x with batch fixed at 16\n",
    "for model_ckpt in MODELS:\n",
    "    base = Path(model_ckpt).stem\n",
    "    lr_group = [\n",
    "        run_name(model_ckpt, IMGSZ, 16, 1.0),\n",
    "        run_name(model_ckpt, IMGSZ, 16, 5.0),\n",
    "        run_name(model_ckpt, IMGSZ, 16, 0.2),\n",
    "    ]\n",
    "    compare_runs(PROJECT_ROOT, lr_group, title=f\"{base} LR Sweep (batch=16)\")\n",
    "\n",
    "# Batch sweep groups: for each model, compare b8 vs b16 vs b32 with lr fixed at 1x\n",
    "for model_ckpt in MODELS:\n",
    "    base = Path(model_ckpt).stem\n",
    "    batch_group = [\n",
    "        run_name(model_ckpt, IMGSZ, 8, 1.0),\n",
    "        run_name(model_ckpt, IMGSZ, 16, 1.0),\n",
    "        run_name(model_ckpt, IMGSZ, 32, 1.0),\n",
    "    ]\n",
    "    compare_runs(PROJECT_ROOT, batch_group, title=f\"{base} Batch Sweep (lr=1x)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
